{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f399ace",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eafb7b",
   "metadata": {},
   "source": [
    "## What's a quantum autoencoder and why should you care?\n",
    "\n",
    "Quantum autoencoders are awesome but you may be wondering what's even a normal autoencoder and what benefits come from it. To answer this we must give a brief overview of classical autoencoders. In the deep learning field it is common to see/use huge neural networks (a neural network it's just a set of interconected neurons). So it would be awesome to use less neurons to accomplish some task that we migth want to do with our neural network. That is the porpuose of an autoencoder, to generate the same results using a lesser amount of neurons. You can see this process graphically with the following picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6355cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71447651",
   "metadata": {},
   "source": [
    "Now, a quantum autoencoder applies the same principle of a classical autoencoder but instead of applying the process to neurons we apply the proccess to a statevector. So informally, a quantum state autoencoder is a circuit that takes a qauntum circuit as a parameter and it outputs another qauntum circuit that has the same properties as the original circuit but uses a smaller amount of qubits. This is a great idea because as you might know we don't get access to a lot of resources in NISQ machines so by applying a QAE we can reduce the use of those resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9352abc",
   "metadata": {},
   "source": [
    "Graphically, a quantum state autoencoder can be seen as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18920ab9",
   "metadata": {},
   "source": [
    "The general process to construct a quantum autoencoder is:\n",
    "- Generate a statevector that we want to reduce.\n",
    "- Create an anzast for a set of parameters theta\n",
    "- Get the cost of the quantum circuit by comparing the original state with the restored state from the QAE.\n",
    "- Optimize the paramters by using a classical optimization routine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5990ba7",
   "metadata": {},
   "source": [
    "More formally we can define all this process as:\n",
    "Let {$\\braket{0|0}$\\}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c686570",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "Now that we saw what is and why autoencoders matter we propose in the following post how to construct one, step by step. And even further, We are going to apply it to a variational circuit that classifies images to show the capabilities of a quantum autoencoder. So the contents of this post are:\n",
    "- First, We present how to build a quantum autoencoder.\n",
    "- Then, We present a variational circuit to classify images.\n",
    "- After that, We connect the variational circuit to the quantum autoencoder.\n",
    "- Then, We present the results of the classifications.\n",
    "- Finally we make some conclusions and present the list of references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
